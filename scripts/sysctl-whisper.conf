# =============================================================================
# Whisper WebSocket Server - Kernel Tuning for 1M Concurrent Connections
# =============================================================================
#
# Apply with:  sudo sysctl -p scripts/sysctl-whisper.conf
# Or run:      sudo ./scripts/tune-kernel.sh
#
# Designed for a production WebSocket server handling ~1,000,000 simultaneous
# connections. Settings are conservative enough for a 16GB RAM development
# machine while being production-ready for larger hosts.
#
# NOTE (Docker): When running in Docker, sysctl settings are applied at the
# HOST kernel level. All containers share the host kernel, so these settings
# must be applied on the Docker host, not inside containers. Some settings
# (e.g., net.*) may also need --sysctl flags in docker run / docker-compose.
# =============================================================================

# -----------------------------------------------------------------------------
# File Descriptors
# -----------------------------------------------------------------------------
# Each WebSocket connection consumes 1 file descriptor. With a target of
# 1,000,000 connections we need at least 1M FDs plus overhead for:
#   - Redis connections (~100)
#   - NATS connections (~100)
#   - Log files, config files, listeners (~50)
#   - Epoll internals
# Setting to 2M provides comfortable headroom.
fs.file-max = 2097152
fs.nr_open = 2097152

# -----------------------------------------------------------------------------
# TCP / Socket Core Settings
# -----------------------------------------------------------------------------
# Maximum number of connections queued for acceptance by listen().
# Under burst conditions (e.g., reconnection storms after a deploy),
# the backlog can spike well beyond the default 128.
net.core.somaxconn = 65535

# Maximum number of packets queued on the INPUT side when the interface
# receives packets faster than the kernel can process them.
net.core.netdev_max_backlog = 65535

# TCP receive/send buffer sizes: min, default, max (bytes)
# WebSocket frames in Whisper are small (typically < 4KB for chat messages).
# Keeping default buffers small (8KB) means each connection uses ~16KB of
# kernel memory for buffers, allowing ~1M connections in ~16GB.
# The max is set high (16MB) for the rare case of large transfers.
net.ipv4.tcp_rmem = 4096 8192 16384
net.ipv4.tcp_wmem = 4096 8192 16384
net.core.rmem_default = 8192
net.core.wmem_default = 8192
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216

# TCP memory auto-tuning (units: pages, typically 4KB each)
#   min      = 786432  pages  (~3 GB)  - below this, TCP does not bother freeing memory
#   pressure = 1048576 pages  (~4 GB)  - TCP starts to reduce memory usage
#   max      = 1572864 pages  (~6 GB)  - hard ceiling for all TCP sockets combined
# At 1M connections with ~16KB per connection the working set is ~16GB,
# but most of that is in user-space buffers; kernel TCP memory is lower.
net.ipv4.tcp_mem = 786432 1048576 1572864

# -----------------------------------------------------------------------------
# TCP Optimization
# -----------------------------------------------------------------------------
# TCP Fast Open (TFO) - saves a round trip on connection establishment.
# Value 3 = enabled for both client (1) and server (2) roles.
# Useful when Whisper nodes connect to each other or to Redis/NATS.
net.ipv4.tcp_fastopen = 3

# Allow reuse of TIME_WAIT sockets for new outbound connections when the
# protocol state allows it. Critical during rolling restarts when thousands
# of connections cycle through TIME_WAIT.
net.ipv4.tcp_tw_reuse = 1

# Reduce FIN_WAIT2 timeout from the default 60s to 15s.
# Dead or abandoned connections release their resources faster.
net.ipv4.tcp_fin_timeout = 15

# Maximum number of TCP sockets not attached to any user file handle
# (orphans). At scale, network blips can temporarily orphan many sockets.
# Default (~8192) is too low for 1M connections.
net.ipv4.tcp_max_orphans = 262144

# Maximum SYN backlog - the queue of half-open connections waiting for
# the final ACK of the three-way handshake. Must be high enough to absorb
# reconnection bursts.
net.ipv4.tcp_max_syn_backlog = 65535

# TCP window scaling (RFC 1323). Allows window sizes larger than 64KB.
# Required for the high rmem_max / wmem_max values above.
net.ipv4.tcp_window_scaling = 1

# Expand the ephemeral port range for outbound connections.
# Whisper servers connect outbound to Redis, NATS, and peer nodes.
# Default range (32768-60999) = ~28K ports, which can be exhausted when
# many backend connections churn. 1024-65535 = ~64K ports.
net.ipv4.ip_local_port_range = 1024 65535

# -----------------------------------------------------------------------------
# TCP Keepalive
# -----------------------------------------------------------------------------
# Detect dead connections faster than the default (7200s / 75s / 9 probes).
# With these settings a dead peer is detected in:
#   300s + (30s * 5) = 450 seconds (~7.5 minutes)
# This complements the application-level WebSocket ping/pong.
net.ipv4.tcp_keepalive_time = 300
net.ipv4.tcp_keepalive_intvl = 30
net.ipv4.tcp_keepalive_probes = 5

# -----------------------------------------------------------------------------
# Epoll
# -----------------------------------------------------------------------------
# Maximum number of file descriptors that a single user can watch with
# epoll. Go's runtime netpoller uses epoll on Linux, and each WebSocket
# connection is registered with the epoll instance. Must be >= file-max.
fs.epoll.max_user_watches = 2097152
